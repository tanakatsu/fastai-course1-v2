{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from fastai.nlp import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from torchtext import vocab, data, datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMBD dataset and the sentiment classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [large movie view dataset](http://ai.stanford.edu/~amaas/data/sentiment/) contains a collection of 50,000 reviews from IMDB. The dataset contains an even number of positive and negative reviews. The authors considered only highly polarized reviews. A negative review has a score ≤ 4 out of 10, and a positive review has a score ≥ 7 out of 10. Neutral reviews are not included in the dataset. The dataset is divided into training and test sets. The training set is the same 25,000 labeled reviews.\n",
    "\n",
    "The **sentiment classification task** consists of predicting the polarity (positive or negative) of a given text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the dataset, in your terminal run the following commands:\n",
    "\n",
    "`wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz`\n",
    "\n",
    "`gunzip aclImdb_v1.tar.gz`\n",
    "\n",
    "`tar -xvf aclImdb_v1.tar`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true
   },
   "source": [
    "### Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sl=1000\n",
    "vocab_size=200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "PATH='data/aclImdb/'\n",
    "\n",
    "names = ['neg','pos']\n",
    "trn,trn_y = texts_labels_from_folders(f'{PATH}train',names)\n",
    "val,val_y = texts_labels_from_folders(f'{PATH}test',names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here is the text of the first review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is the first of these \"8 Films To Die For\" collection that I\\'ve seen and it\\'s certainly not made me want to see any of the rest...although I\\'ve heard at least a couple of them are decent. I don\\'t know, this wasn\\'t terrible but it didn\\'t really do much for me. Your basic dysfunctional cannibal family in suburbia kind of thing, mom & dad died, the family sold the farm & moved to San Francisco (?) where they continued to bring home stray food sources whenever possible. The best part of this was the creepy Goth sister, who of course invites a friend over from school that never leaves. Anyway, of course we have a butcher shop in the basement and so on and so on. This family is sort of like the white-bread version of the Sawyer Clan, they\\'re nasty & they do bad things but they ain\\'t go no soul. I see a lot of reviews from people that liked this, and I guess I don\\'t know what I missed, but I found it to be very mediocre & I wouldn\\'t recommend it to anyone, really. 4 out of 10.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "[`CountVectorizer`](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) converts a collection of text documents to a matrix of token counts (part of `sklearn.feature_extraction.text`). Here is how you specify parameters to the CountVectorizer. We will be working with the top 200000 unigrams, bigrams and trigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "veczr = CountVectorizer(ngram_range=(1,3), tokenizer=tokenize, max_features=vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In the next line `fit_transform(trn)` computes the vocabulary and other hyparameters learned from the training set. It also transforms the training set. Since we have to apply the *same transformation* to your validation set, the second line uses just the method `transform(val)`. `trn_term_doc` and `val_term_doc` are sparse matrices. `trn_term_doc[i]` represents training document $i$ and it is binary (it has a $1$ for each vocabulary n-gram present in document $i$  and $0$ otherwise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trn_term_doc = veczr.fit_transform(trn) # scipy.sparse.csr.csr_matrix\n",
    "val_term_doc = veczr.transform(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 200000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_term_doc.shape # (dataset size, vocabulary size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analyzer': 'word',\n",
       " 'binary': False,\n",
       " 'decode_error': 'strict',\n",
       " 'dtype': numpy.int64,\n",
       " 'encoding': 'utf-8',\n",
       " 'input': 'content',\n",
       " 'lowercase': True,\n",
       " 'max_df': 1.0,\n",
       " 'max_features': 200000,\n",
       " 'min_df': 1,\n",
       " 'ngram_range': (1, 3),\n",
       " 'preprocessor': None,\n",
       " 'stop_words': None,\n",
       " 'strip_accents': None,\n",
       " 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'tokenizer': <function fastai.text.tokenize>,\n",
       " 'vocabulary': None}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "veczr.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# here is the vocabulary\n",
    "vocab = veczr.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['! \" and', '! \" as', '! \" at', '! \" but', '! \" for']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[50:55]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first model is a version of logistic regression with Naive Bayes features described [here](https://www.aclweb.org/anthology/P12-2018). For every document we compute binarized features as described above. Each feature if multiplied by a log-count ratio (see below for explanation). A logitic regression model is then trained to predict sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how to define **log-count ratio** for a feature $f$:\n",
    "\n",
    "$\\text{log-count ratio} = \\log \\frac{\\text{ratio of feature $f$ in positive documents}}{\\text{ratio of feature $f$ in negative documents}}$\n",
    "\n",
    "where ratio of feature $f$ in positive documents is the number of times a positive document has a feature divided by the number of positive documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is how we get a model from a bag of words\n",
    "md = TextClassifierData.from_bow(trn_term_doc, trn_y, val_term_doc, val_y, sl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://forums.fast.ai/t/howto-installation-on-windows/10439/87\n",
    "\n",
    "# You have to change code in fastai/metrics.py\n",
    "\n",
    "# Before\n",
    "#def accuracy_multi(preds, targs, thresh):\n",
    "#    return ((preds>thresh)==targs).float().mean()\n",
    "\n",
    "# After\n",
    "#def accuracy_multi(preds, targs, thresh):\n",
    "#    return ((preds>thresh).float()==targs).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e10744046f2a4eed87c306eefa42446b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   <lambda>                     \n",
      "    0      0.068083   0.122717   0.916408  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12271736, 0.9164082481123298]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner = md.dotprod_nb_learner()\n",
    "learner.fit(0.02, 1, wds=1e-5, cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb26ae0cf5a849199f92bfcf856553d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   <lambda>                     \n",
      "    0      0.059264   0.10752    0.923489  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10751964, 0.9234894501888539]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner = md.dotprod_nb_learner()\n",
    "learner.fit(0.02, 1, wds=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is use `CountVectorizer` with a different set of parameters. In particular ngram_range by default is set to (1, 1)so we will get unigram features. Note that we are specifiying our own `tokenize` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "veczr =  CountVectorizer(tokenizer=tokenize)\n",
    "trn_term_doc = veczr.fit_transform(trn)\n",
    "val_term_doc = veczr.transform(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how to compute the $\\text{log-count ratio}$ `r`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75132"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check vocabulary size\n",
    "len(veczr.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=trn_term_doc # scipy.sparse.csr.csr_matrix (25000, 75132)\n",
    "y=trn_y # (25000,)\n",
    "\n",
    "p = x[y==1].sum(0)+1 # numpy.matrixlib.defmatrix.matrix (1, 75132), add 1 to avoid zero dividing\n",
    "q = x[y==0].sum(0)+1 # numpy.matrixlib.defmatrix.matrix (1, 75132), add 1 to avoid zero dividing\n",
    "r = np.log((p/p.sum())/(q/q.sum())) # (1, 75132)\n",
    "b = np.log(len(p)/len(q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### minimum example\n",
    "\n",
    "```\n",
    "x[y ==1]: [[3, 0, 1]]\n",
    "x[y == 0]: [[1, 1, 0]]\n",
    "\n",
    "p = [4, 1, 2]\n",
    "q = [2, 2, 1]\n",
    "\n",
    "p / p.sum() = [ 0.57142857,  0.14285714,  0.28571429]\n",
    "q / q.sum() = [ 0.4,  0.4,  0.2]\n",
    "\n",
    "r = np.log((p/p.sum()) / (q/q.sum())) = [ 0.35667494, -1.02961942,  0.35667494]\n",
    "b = np.log(len(p) / len(q)) = 0.0\n",
    "\n",
    "# prediction\n",
    "val = [[1, 1, 0]]\n",
    "val @ r.T + b = [[-0.67294448]] # => 0\n",
    "```    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the formula for Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8074"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_preds = val_term_doc @ r.T + b # (25000, 75132) * (75132, 1) + b\n",
    "preds = pre_preds.T>0\n",
    "(preds==val_y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82624"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_preds = val_term_doc.sign() @ r.T + b\n",
    "preds = pre_preds.T>0\n",
    "(preds==val_y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3)\t8\n",
      "  (0, 8)\t1\n",
      "  (0, 13)\t2\n",
      "  (0, 15)\t8\n",
      "  (0, 16)\t6\n",
      "  (0, 59)\t1\n",
      "  (0, 1039)\t6\n",
      "  (0, 1041)\t6\n",
      "  (0, 1050)\t2\n",
      "  (0, 1362)\t1\n",
      "  (0, 2619)\t1\n",
      "  (0, 2726)\t2\n",
      "  (0, 3219)\t1\n",
      "  (0, 3817)\t2\n",
      "  (0, 3862)\t1\n",
      "  (0, 5221)\t1\n",
      "  (0, 5234)\t1\n",
      "  (0, 5254)\t1\n",
      "  (0, 5472)\t2\n",
      "  (0, 6304)\t1\n",
      "  (0, 7063)\t1\n",
      "  (0, 7229)\t1\n",
      "  (0, 8696)\t6\n",
      "  (0, 9854)\t1\n",
      "  (0, 9936)\t1\n",
      "  :\t:\n",
      "  (0, 65309)\t1\n",
      "  (0, 66400)\t1\n",
      "  (0, 66441)\t1\n",
      "  (0, 66458)\t6\n",
      "  (0, 66554)\t1\n",
      "  (0, 66580)\t1\n",
      "  (0, 66596)\t1\n",
      "  (0, 66743)\t1\n",
      "  (0, 67182)\t1\n",
      "  (0, 67252)\t5\n",
      "  (0, 67451)\t1\n",
      "  (0, 68935)\t1\n",
      "  (0, 72232)\t1\n",
      "  (0, 72337)\t5\n",
      "  (0, 72400)\t1\n",
      "  (0, 72506)\t1\n",
      "  (0, 72745)\t2\n",
      "  (0, 72747)\t1\n",
      "  (0, 72896)\t1\n",
      "  (0, 73451)\t1\n",
      "  (0, 73453)\t1\n",
      "  (0, 73488)\t1\n",
      "  (0, 74251)\t1\n",
      "  (0, 74478)\t2\n",
      "  (0, 74503)\t1\n"
     ]
    }
   ],
   "source": [
    "print(val_term_doc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3)\t1\n",
      "  (0, 8)\t1\n",
      "  (0, 13)\t1\n",
      "  (0, 15)\t1\n",
      "  (0, 16)\t1\n",
      "  (0, 59)\t1\n",
      "  (0, 1039)\t1\n",
      "  (0, 1041)\t1\n",
      "  (0, 1050)\t1\n",
      "  (0, 1362)\t1\n",
      "  (0, 2619)\t1\n",
      "  (0, 2726)\t1\n",
      "  (0, 3219)\t1\n",
      "  (0, 3817)\t1\n",
      "  (0, 3862)\t1\n",
      "  (0, 5221)\t1\n",
      "  (0, 5234)\t1\n",
      "  (0, 5254)\t1\n",
      "  (0, 5472)\t1\n",
      "  (0, 6304)\t1\n",
      "  (0, 7063)\t1\n",
      "  (0, 7229)\t1\n",
      "  (0, 8696)\t1\n",
      "  (0, 9854)\t1\n",
      "  (0, 9936)\t1\n",
      "  :\t:\n",
      "  (0, 65309)\t1\n",
      "  (0, 66400)\t1\n",
      "  (0, 66441)\t1\n",
      "  (0, 66458)\t1\n",
      "  (0, 66554)\t1\n",
      "  (0, 66580)\t1\n",
      "  (0, 66596)\t1\n",
      "  (0, 66743)\t1\n",
      "  (0, 67182)\t1\n",
      "  (0, 67252)\t1\n",
      "  (0, 67451)\t1\n",
      "  (0, 68935)\t1\n",
      "  (0, 72232)\t1\n",
      "  (0, 72337)\t1\n",
      "  (0, 72400)\t1\n",
      "  (0, 72506)\t1\n",
      "  (0, 72745)\t1\n",
      "  (0, 72747)\t1\n",
      "  (0, 72896)\t1\n",
      "  (0, 73451)\t1\n",
      "  (0, 73453)\t1\n",
      "  (0, 73488)\t1\n",
      "  (0, 74251)\t1\n",
      "  (0, 74478)\t1\n",
      "  (0, 74503)\t1\n"
     ]
    }
   ],
   "source": [
    "# The sign function returns -1 if x < 0, 0 if x==0, 1 if x > 0.\n",
    "print(val_term_doc.sign()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how we can fit regularized logistic regression where the features are the unigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88284"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LogisticRegression(C=0.1, fit_intercept=False, dual=True)\n",
    "m.fit(x, y) # x: (25000, 75132), y: (25000,)\n",
    "preds = m.predict(val_term_doc)\n",
    "(preds==val_y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bigram with NB features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the model before but with bigram features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "veczr =  CountVectorizer(ngram_range=(1,2), tokenizer=tokenize)\n",
    "trn_term_doc = veczr.fit_transform(trn)\n",
    "val_term_doc = veczr.transform(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=trn_y\n",
    "x=trn_term_doc.sign()\n",
    "val_x = val_term_doc.sign()\n",
    "p = x[y==1].sum(0)+1\n",
    "q = x[y==0].sum(0)+1\n",
    "r = np.log((p/p.sum())/(q/q.sum()))\n",
    "b = np.log(len(p)/len(q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we fit regularized logistic regression where the features are the bigrams. Bigrams are giving us 2% boost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90272"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LogisticRegression(C=0.1, fit_intercept=False)\n",
    "m.fit(x, y);\n",
    "\n",
    "preds = m.predict(val_x)\n",
    "(preds.T==val_y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the $\\text{log-count ratio}$ `r`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.68627,  0.68627, -0.70002, ...,  0.68627, -0.70002, -0.70002]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we fit regularized logistic regression where the features are the bigrams multiplied by the $\\text{log-count ratio}$. We are getting an extra boost for the normalization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_nb = x.multiply(r)\n",
    "m = LogisticRegression(dual=True, C=1, fit_intercept=False)\n",
    "m.fit(x_nb, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_x_nb must be defined\n",
    "val_x_nb = val_x.multiply(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9148"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = m.coef_.T\n",
    "preds = (val_x_nb @ w + m.intercept_)>0 # The @ (at) operator is intended to be used for matrix multiplication. See https://stackoverflow.com/questions/27385633/what-is-the-symbol-for-in-python\n",
    "(preds.T==val_y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an interpolation between Naive Bayes the regulaized logistic regression approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9164"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta=0.25\n",
    "\n",
    "val_x_nb = val_x.multiply(r)\n",
    "w = (1-beta)*m.coef_.mean() + beta*m.coef_.T\n",
    "preds = (val_x_nb @ w + m.intercept_)>0\n",
    "(preds.T==val_y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2 = w.T[0]*r.A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9164"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = (val_x @ w2 + m.intercept_)>0\n",
    "(preds.T==val_y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Baselines and Bigrams: Simple, Good Sentiment and Topic Classification. Sida Wang and Christopher D. Manning [pdf](https://www.aclweb.org/anthology/P12-2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Unused helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class EzLSTM(nn.LSTM):\n",
    "    def __init__(self, input_size, hidden_size, *args, **kwargs):\n",
    "        super().__init__(input_size, hidden_size, *args, **kwargs)\n",
    "        self.num_dirs = 2 if self.bidirectional else 1\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = c0 = Variable(torch.zeros(self.num_dirs,x.size(1),self.hidden_size)).cuda()\n",
    "        outp,_ = super().forward(x, (h0,c0))\n",
    "        return outp[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def init_wgts(m, last_l=-2):\n",
    "    c = list(m.children())\n",
    "    for l in c:\n",
    "        if isinstance(l, nn.Embedding): \n",
    "            l.weight.data.uniform_(-0.05,0.05)\n",
    "        elif isinstance(l, (nn.Linear, nn.Conv1d)):\n",
    "            xavier_uniform(l.weight.data, gain=calculate_gain('relu'))\n",
    "            l.bias.data.zero_()\n",
    "    xavier_uniform(c[last_l].weight.data, gain=calculate_gain('linear'));\n",
    "\n",
    "class SeqSize(nn.Sequential):\n",
    "    def forward(self, x):\n",
    "        for l in self.children():\n",
    "            x = l(x)\n",
    "            print(x.size())\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "104px",
    "width": "251px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "04292643c86e455c9279c9d0cbe7591c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "10a9fdc8e91148c9bdaa8a4a3fad6d5b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_3e65bb3a153f4e11b77e4bae73036173",
       "style": "IPY_MODEL_6e4a26fd9d204ff6b2807b1de277e624",
       "value": "100% 1/1 [00:25&lt;00:00, 25.41s/it]"
      }
     },
     "15f543ded2dd4ab1b4bd9492ecc80176": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "194f12cd2de3404e845050ddbd5afc3c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "25eceea742894ad3869d692b0f80fef6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_27a9a3fe028643759767da48219b39ae",
        "IPY_MODEL_ed994da251e5433b998bf6dd6e6c8fb5"
       ],
       "layout": "IPY_MODEL_5b238d5422324170b97ae498c3d332f9"
      }
     },
     "27a9a3fe028643759767da48219b39ae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "IntProgressModel",
      "state": {
       "bar_style": "danger",
       "description": "Epoch",
       "layout": "IPY_MODEL_d7efb5439d814b8e8ec9921b78897fbb",
       "max": 1,
       "style": "IPY_MODEL_9bd5885c40df46819e1e94c3f0e183a4"
      }
     },
     "315dab4f30d9472ca5a13c93293e3991": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_86161c4717fc4ae09c145356a33a84fc",
        "IPY_MODEL_10a9fdc8e91148c9bdaa8a4a3fad6d5b"
       ],
       "layout": "IPY_MODEL_df88a8f4d2b64ad2941ab904d029a17b"
      }
     },
     "3588390ae1fe44229d77d8ceb266dd11": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3cb8a8167c944033b4222ed97b5420d0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_3588390ae1fe44229d77d8ceb266dd11",
       "style": "IPY_MODEL_8916f78e8646424d9b8064c11e29aee4",
       "value": "  0% 0/1 [00:00&lt;?, ?it/s]"
      }
     },
     "3e65bb3a153f4e11b77e4bae73036173": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3f624a1a91dd4dc8a33b6d225b2c2952": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "45caa9c9bc154280853da15419ffbfd3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "45df0aa6352340b6a69af2d30c3113dc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_6e4e2415c26d436faa2b85dac3f43eb6",
       "style": "IPY_MODEL_f9a03585c18144b4a4c06628df6187a4",
       "value": "100% 1/1 [00:25&lt;00:00, 25.60s/it]"
      }
     },
     "4ea816dd1d164c919dd3326e3df3c441": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "IntProgressModel",
      "state": {
       "bar_style": "danger",
       "description": "Epoch",
       "layout": "IPY_MODEL_718e0228e8b44e3f9cdeef5436395901",
       "max": 1,
       "style": "IPY_MODEL_552b6e92888d49b88fd129cc56902caa"
      }
     },
     "552b6e92888d49b88fd129cc56902caa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "5b238d5422324170b97ae498c3d332f9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5dec5d17d58c4a7daff3d523ad9b1afb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "646e71e613c14e73a1b9b394fc9948b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "6834a5af2e984b5aaa0001b823b40e0a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6e4a26fd9d204ff6b2807b1de277e624": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "6e4e2415c26d436faa2b85dac3f43eb6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "718e0228e8b44e3f9cdeef5436395901": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "732d23c9fa1b4fe0963aad1ba199dc8e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7493e01ee93b49e99cbe0fc9c91ecb45": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "IntProgressModel",
      "state": {
       "bar_style": "success",
       "description": "Epoch",
       "layout": "IPY_MODEL_ff97cdaeff4a42feb3e8e552441dd818",
       "max": 1,
       "style": "IPY_MODEL_fbd84c001ca544b386f7e04373ebf65b",
       "value": 1
      }
     },
     "76e08246c8c94f7793d5c7435051e1c4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7d221bc777e1412aa39be77fab562b4c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_eee5081e391f4b56a32370c70536fe78",
       "style": "IPY_MODEL_caf216e9d6b94e62868d5e39a62ad594",
       "value": "100% 1/1 [00:27&lt;00:00, 27.95s/it]"
      }
     },
     "86161c4717fc4ae09c145356a33a84fc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "IntProgressModel",
      "state": {
       "bar_style": "success",
       "description": "Epoch",
       "layout": "IPY_MODEL_732d23c9fa1b4fe0963aad1ba199dc8e",
       "max": 1,
       "style": "IPY_MODEL_8921d91c06b349898d2b013037260af8",
       "value": 1
      }
     },
     "861d8f8fdc8e4bf98c0a02d47a2ac432": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8916f78e8646424d9b8064c11e29aee4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "8921d91c06b349898d2b013037260af8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "9824b05b5f1e42c382e49a57c795caff": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9bd5885c40df46819e1e94c3f0e183a4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "a69bf700fce745638bdad5670b87f43c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "IntProgressModel",
      "state": {
       "bar_style": "success",
       "description": "Epoch",
       "layout": "IPY_MODEL_76e08246c8c94f7793d5c7435051e1c4",
       "max": 1,
       "style": "IPY_MODEL_15f543ded2dd4ab1b4bd9492ecc80176",
       "value": 1
      }
     },
     "a6e1bd01144b4665a43fe81c60ac4a32": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a8c16deea9b744c789b0dc9be103cbf0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_7493e01ee93b49e99cbe0fc9c91ecb45",
        "IPY_MODEL_e30aceb743ba4df2ae1083d2ea6d311c"
       ],
       "layout": "IPY_MODEL_a6e1bd01144b4665a43fe81c60ac4a32"
      }
     },
     "ac2ce95c592a4cd3bd77897ec9e8308c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_4ea816dd1d164c919dd3326e3df3c441",
        "IPY_MODEL_3cb8a8167c944033b4222ed97b5420d0"
       ],
       "layout": "IPY_MODEL_861d8f8fdc8e4bf98c0a02d47a2ac432"
      }
     },
     "caf216e9d6b94e62868d5e39a62ad594": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "d6c2e3701d714270b4f013393aa3b328": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_a69bf700fce745638bdad5670b87f43c",
        "IPY_MODEL_7d221bc777e1412aa39be77fab562b4c"
       ],
       "layout": "IPY_MODEL_9824b05b5f1e42c382e49a57c795caff"
      }
     },
     "d7efb5439d814b8e8ec9921b78897fbb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "df88a8f4d2b64ad2941ab904d029a17b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e30aceb743ba4df2ae1083d2ea6d311c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_3f624a1a91dd4dc8a33b6d225b2c2952",
       "style": "IPY_MODEL_5dec5d17d58c4a7daff3d523ad9b1afb",
       "value": "100% 1/1 [00:27&lt;00:00, 27.79s/it]"
      }
     },
     "ed994da251e5433b998bf6dd6e6c8fb5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_04292643c86e455c9279c9d0cbe7591c",
       "style": "IPY_MODEL_194f12cd2de3404e845050ddbd5afc3c",
       "value": "  0% 0/1 [00:00&lt;?, ?it/s]"
      }
     },
     "eee5081e391f4b56a32370c70536fe78": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f33e2e25291246df9c151a72a31e066d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_fcaf115c754a4083bcd71d1ebc793b2b",
        "IPY_MODEL_45df0aa6352340b6a69af2d30c3113dc"
       ],
       "layout": "IPY_MODEL_45caa9c9bc154280853da15419ffbfd3"
      }
     },
     "f9a03585c18144b4a4c06628df6187a4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "fbd84c001ca544b386f7e04373ebf65b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "fcaf115c754a4083bcd71d1ebc793b2b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "IntProgressModel",
      "state": {
       "bar_style": "success",
       "description": "Epoch",
       "layout": "IPY_MODEL_6834a5af2e984b5aaa0001b823b40e0a",
       "max": 1,
       "style": "IPY_MODEL_646e71e613c14e73a1b9b394fc9948b0",
       "value": 1
      }
     },
     "ff97cdaeff4a42feb3e8e552441dd818": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
